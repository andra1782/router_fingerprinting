import argparse
import datetime
import json
import logging
import re
import sqlite3
import time
from dataclasses import dataclass
from math import isnan

import pandas as pd
from cvss import CVSS2, CVSS3, CVSS4

"""
============================= GLOBALS ============================
"""

logger = logging.getLogger(__name__)
logging.basicConfig(filename='get_cves.log', encoding='utf-8', format='%(asctime)s::%(levelname)s::%(message)s',
                    level=logging.INFO)

con = sqlite3.connect('cve.db')  # db connection

vendor_map = None  # vendor names found using snmp differ from those in the db, so we define a mapping between them


@dataclass
class Env(argparse.Namespace):
    input: str = 'input.csv'
    # Initially, some vendor names from the snmp scans won't be in the `vendor_mapping.json`. First do a dry run,
    # which will report any missing mappings without doing any db operations. After you're sure all necessary mappings
    # were added, re-run the script for real
    dry_run: bool = False
    severity: float = None
    routers_only: bool = False
    verbose_severity: bool = False


# get CLI args
parser = argparse.ArgumentParser()
parser.add_argument('-i', '--input', type=str, default='input.csv', help='path to the input csv file')
parser.add_argument('-n', '--dry-run', action='store_true', help='only log unknown vendors')
parser.add_argument('-s', '--severity', type=float, default=None,
                    help='include severity metrics with severity larger than the provided value in the output')
parser.add_argument('-r', '--routers-only', action='store_true', help='only report CVEs related to routers')
parser.add_argument('-vs', '--verbose-severity', action='store_true',
                    help='increase verbosity of severity metrics by extracting the information encoded in the cvss vector string')
env = Env(**vars(parser.parse_args()))

"""
============================== METHODS =============================
"""

def vendor_resolution(enterprise: str) -> str | None:
    """
    Resolve the vendor shortname given the enterprise name obtained from the scanning. The map is stored in 
    `vendor_mapping.json`. 
    :param enterprise: the `enterprise` field from the scanning results
    :return: the shortname of the vendor, as found in the db
    :raises KeyError: if the enterprise is not found in the mapping. Should be manually added to the mapping file
    """
    global vendor_map
    if vendor_map is None:  # load it once
        with open('vendor_mapping.json', 'r') as f:
            vendor_map = json.load(f)
            
    if isnan(enterprise):
        return None
    
    enterprise = str(int(enterprise)) # they are parsed as floats for some reason
    
    if enterprise in vendor_map:
        return vendor_map[enterprise]

    # logged
    logger.warning(f"Enterprise {enterprise} not found in vendor map. Add it to vendor_mapping.json.")
    return None


def convert_to_date(time: str) -> datetime.date:
    """
    Calculates the date the last boot took place from the snmpEngineTime field.
    :param time: the value of the snmpEngineTime field
    :return: the `datetime.date` representing the date of the last boot
    """
    days_since_reboot = re.search(r'(\d+)d', str(time)).group(1)

    reboot_date = datetime.date.today() - datetime.timedelta(days=int(days_since_reboot))

    return reboot_date.strftime('%Y-%m-%dT%H:%M:%S')



def parse_cvss_vector(vector_string: str) -> dict[str, str]:
    """
    CVSS vector strings encode a lot of information about the severity of a vulnerability. This method takes a 
    cvss vector string and parses it into a dictionary. This is only used when the `--verbose-severity` flag is
    set, since it produces a lot of output. 
    
    You can check https://www.first.org/cvss/specification-document for 
    information on how the 4.0 version is structured.
    :param vector_string: The cvss vector string of the CVE
    :return: A dictionary where the keys are the names of the metrics and the values are the values of the metrics.
    """
    cvss_version = vector_string[5:8]

    return {
        '2.0': CVSS2,
        '3.0': CVSS3,
        '3.1': CVSS3,
        '4.0': CVSS4,
    }[cvss_version](vector_string).as_json()


def find_cves(scans: pd.DataFrame) -> dict[str, list[dict[str, object]]] | None:
    """
    Queries the database for any CVEs for the vendor that were published after the date of the last boot.
    :param scans: a row like in the input csv
    :param ip_cve_mapping: mutable dictionary that is updated with the found CVEs for the ip
    :return: nothing, it updates the dictionary instead
    """
    # Filter out rows where enterprise is 'unknown'
    scans = scans[scans['enterprise'] != 'nan']

    ips = scans['ip'].to_list()
    vendor_shortname = scans['enterprise'].apply(vendor_resolution).to_list()
    reboot_date = scans['snmpEngineTime'].apply(convert_to_date).to_list()

    if env.dry_run:
        return None

    selection = 'm.cveId'
    if env.severity is not None and env.verbose_severity:
        selection += ', m.vectorString'
    elif env.severity is not None:
        selection += ', m.baseScore, m.baseSeverity'

    values = [tup for tup in zip(ips, reboot_date, vendor_shortname) if tup[2] is not None]
    query_values = ', '.join(['(' + ', '.join([f'\'{entry}\'' for entry in value]) + ')' for value in values])

    querry = f"""
        WITH date_assigner_pairs AS (VALUES {query_values})
        SELECT d.column1 as ip, {selection}
        FROM date_assigner_pairs d
        LEFT JOIN cve_metadata m ON
                    m.datePublished > d.column2
            AND     m.assignerShortName = d.column3
            {'AND   m.relatedToRouters < 2' if env.routers_only else ''}
            {'AND   m.baseScore >= ' + str(env.severity) if env.severity is not None else ''}
    """

    print('Starting query')
    start = time.time()
    cve_list = (pd.read_sql_query(querry, con)
                .set_index('ip') # need to do this to avoid weird stuff
                .groupby('ip')
                .apply( lambda x: x.to_dict(orient='records')) 
                .to_dict())
    print(f'Queried and processed {len(ips)} items in {time.time() - start:.2f} seconds')

    if env.verbose_severity:
        for ip, ip_cves in cve_list.items():
            for i, cve in enumerate(ip_cves):
                cve_list[ip][i] |= parse_cvss_vector(cve['vectorString'])
    return cve_list


if __name__ == '__main__':
    df = pd.read_csv(env.input)
    df.reset_index()

    # Remove rows with unknown enterprise
    df = df[df['enterprise'] != 'unknown']

    ip_cve_mapping = find_cves(df)

    # dump results to a JSON file
    with open('found_cves.json', 'w') as f:
        print(f'Dumping results to found_cves.json')
        json.dump(ip_cve_mapping, f, indent=2)
