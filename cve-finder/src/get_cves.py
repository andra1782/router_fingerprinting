import argparse
import os
import sqlite3
import time
from dataclasses import dataclass
from typing import Literal

import pandas as pd

from custom_loggers import logger

"""
================================== GLOBALS =================================
"""

con = sqlite3.connect('../cve3.db')  # db connection
cur = con.cursor()

vendor_map = None  # vendor names found using snmp differ from those in the db, so we define a mapping between them


@dataclass
class Env(argparse.Namespace):
    severity: float
    exploitability_score: Literal['LOW', 'HIGH']
    routers_only: bool
    countries: list[str]
    explain_query: bool
    input_tags: str
    router_identifier: Literal['IP', 'ENGINEID', 'SNMP']

    def dump_run_config(self):
        logger.debug('=================================================')
        logger.debug('Running program with the following configuration:')

        for var, val in vars(self).items():
            logger.debug(f'{var:>20} {val}')

        logger.debug('=================================================')


# get CLI args
parser = argparse.ArgumentParser()
parser.add_argument('-s', '--severity', type=float, default=None,
                    help='include severity metrics with severity larger than the provided value in the output')
parser.add_argument('-e', '--exploitability-score', type=str, choices=['LOW', 'HIGH'], default=None,
                    help='include only CVEs with this exploitability score')
parser.add_argument('-r', '--routers-only', action='store_true', help='only report CVEs related to routers')
parser.add_argument('-q', '--explain-query', action='store_true', help='explain the query that is being run')
parser.add_argument('-it', '--input-tags', type=str, required=True, default='../bgp-tools/csvs',
                    help='path to directory containing tags for asns')
parser.add_argument('-id', '--router-identifier', type=str, required=True, choices=['IP', 'ENGINEID', 'SNMP'],
                    default='ENGINEID', help='how to identify unique routers')
parser.add_argument('--countries', nargs='*', type=str, default=[])

env = Env(**vars(parser.parse_args()))

"""
=================================== METHODS ==================================
"""


def build_query() -> str:
    conditions = ['m.datePublished > d.snmpRebootDate', 'm.shortVendorName == d.enterprise', ]
    selections = [
        'm.cveId',
        'd.ip',
        'd.engineIDData',
        'd.snmpEngineBoots',
        'd.snmpRebootDate',
        'm.shortVendorName',
        'd.asn',
        'd.country',
    ]

    # build selected columns
    if env.severity is not None:
        selections.append('m.baseScore')

    if env.exploitability_score is not None:
        selections.append('m.exploitabilityScore')

    # build conditions
    if env.routers_only:
        # 0 = for sure related; 
        # 1 = did not have a description, so not sure; 
        # 2 = could not find keywords in the description
        conditions.append('m.relatedToRouters < 2')

    if env.severity is not None:
        conditions.append(f'm.baseScore >= {env.severity}')

    if env.exploitability_score is not None:
        conditions.append(f'm.exploitabilityScore == "{env.exploitability_score}"')

    if env.countries:
        country_list = "','".join(env.countries)
        conditions.append(f'd.country IN (\'{country_list}\')')

    # groupby condition
    group_by = {
        'IP': 'ip',
        'ENGINEID': 'engineIDData',
        'SNMP': 'snmpEngineBoots, snmpRebootDate'
    }[env.router_identifier]

    return f"""
        SELECT {', '.join(selections)}
        FROM (SELECT * FROM scan_results WHERE 
            engineIDData NOT NULL
            AND snmpEngineBoots > 0
            AND enterprise NOT NULL
        GROUP BY {group_by}) d
        JOIN (SELECT * FROM cve_metadata NATURAL JOIN cve_vendor NATURAL JOIN vendors) m 
            ON {' AND '.join(conditions)}
    """


def find_cves() -> pd.DataFrame | None:
    """
    Queries the database for any CVEs for the vendor that were published after the date of the last boot.
    """
    query = build_query()

    if env.explain_query:
        logger.debug(query)
        logger.debug(con.execute(f'EXPLAIN QUERY PLAN {query}').fetchall())

    logger.info('Starting query')
    start = time.time()
    cve_list = (pd.read_sql_query(query, con))
    logger.info(f'Queried and processed {len(cve_list)} items in {time.time() - start:.2f} seconds')

    return cve_list


def load_tags(dir: str) -> pd.DataFrame | None:
    try:

        if not os.path.isdir(dir):
            logger.error(f"dir {dir} doesn't exist")
            return None

        dfs = []

        for filename in os.listdir(dir):
            if filename.endswith('.csv') and filename != "feeder.csv":
                filepath = os.path.join(dir, filename)
                try:
                    df = pd.read_csv(filepath, header=None, names=['ASN', 'Organization'])
                    df['source_file'] = filename.split(".")[0]
                    df = df.iloc[:, [2, 1, 0]]
                    df['ASN'] = df['ASN'].astype(str).str.upper().str.removeprefix("AS")
                    dfs.append(df)

                except Exception as e:
                    logger.error(f"{filename} failed; error: {e}")

        if dfs:
            res = pd.concat(dfs, ignore_index=True)
            res.columns = ["Tag", "Organization Name", "ASN"]
            res.to_csv(r'tags.csv', index=None, sep=';', mode='w')
            return res
        else:
            logger.warn("No CSV files found.")
            return None
    except Exception as e:
        logger.error(f"LOL{str(e)}")


if __name__ == '__main__':
    env.dump_run_config()
    engineid_cve_mapping: pd.DataFrame = find_cves()

    # dump results to a CSV file
    output_no_tags_path = '../found_cves.csv'

    logger.info(f"Saved results (no tags) to {output_no_tags_path}")
    engineid_cve_mapping.to_csv('../found_cves.csv', mode='w', index=False)

    if env.input_tags:
        logger.info("Adding tags to output")
        tags_df = load_tags(env.input_tags)

        tags_df.to_csv('tags.csv', index=False)

        original_length = len(engineid_cve_mapping)

        if tags_df is not None and engineid_cve_mapping is not None:
            tags_df['ASN'] = tags_df['ASN'].astype(str).str.strip()
            engineid_cve_mapping['asn'] = engineid_cve_mapping['asn'].astype(str).str.strip()

            logger.info("Aggregating tags per asn")
            tags_agg = tags_df.groupby('ASN')['Tag'].apply(lambda x: ';'.join(sorted(set(x)))).reset_index()

            logger.info("Merging aggregated tags")

            merged = pd.merge(
                engineid_cve_mapping,
                tags_agg,
                left_on='asn',
                right_on='ASN',
                how='left'
            ).drop(columns=['ASN'])

            merged['Tag'] = merged['Tag'].fillna('UNKNOWN')

            merged.rename(columns={'Tag': 'tag'}, inplace=True)

            columns_order = ['ip', 'cveId', 'shortVendorName', 'engineIDData', 'snmpEngineBoots', 'snmpRebootDate',
                             'asn', 'tag', 'country']
            if 'baseScore' in merged.columns:
                columns_order += ['baseScore']
            merged = merged[columns_order]

            output_with_tags_path = '../found_cves_with_tags.csv'
            merged.to_csv(output_with_tags_path, index=False)

            logger.info(f"Saved results with tags to {output_with_tags_path}")
            logger.info(f"Original CVE rows: {original_length}")
            logger.info(f"Final tagged rows: {len(merged)}")
