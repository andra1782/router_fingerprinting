import argparse
import pandas as pd
import os
import requests
from bs4 import BeautifulSoup
import time
import random 




def parse_arguments():
    parser = argparse.ArgumentParser(description='Process CVE CSV and extract top ASN data.')
    parser.add_argument('--input_csv', default='found_cves.csv', help='Input CSV file name (default: found_cves.csv)')
    parser.add_argument('--base_score', type=float, default=None, help='Minimum base score to consider (optional)')
    parser.add_argument('--output_file', default='top_asns.csv', help='Output CSV file name (default: top_asns.csv)')
    parser.add_argument('--count_only', action='store_true', help='If set, output unique CVE count instead of listing them')
    return parser.parse_args()


def fetch_network_type_value(asn):
    base_url = "https://bgp.tools/as/"
    url = f"{base_url}{asn}"
    headers = {
        "User-Agent": (
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
            "AppleWebKit/537.36 (KHTML, like Gecko) "
            "Chrome/114.0.0.0 Safari/537.36"
        ),
        "Accept-Language": "en-US,en;q=0.9",
    }

    try:
        response = requests.get(url, headers=headers, timeout=10)
        response.raise_for_status()
        soup = BeautifulSoup(response.text, 'html.parser')

        for dt in soup.find_all('dt'):
            if dt.get_text(strip=True) == 'Network type':
                dd = dt.find_next_sibling('dd')
                if dd:
                    res = dd.get_text(strip=True)
                    print(f"AS{asn}->{res}")
                    return res
                else:
                    return "Unknown"
            
            wait_time = random.uniform(1.5, 4.0)
            time.sleep(wait_time)
    except Exception as e:
        print(f"Failed to fetch for ASN {asn}: {e}")
        return "Unknown"

def main():
    args = parse_arguments()

    script_dir = os.path.dirname(os.path.abspath(__file__))
    base_dir = os.path.abspath(os.path.join(script_dir, '..'))
    input_path = os.path.join(base_dir, args.input_csv)
    output_path = os.path.join(base_dir, args.output_file)

    df = pd.read_csv(input_path)

    if args.base_score is not None:
        df = df[df['baseScore'] >= args.base_score]

    if df.empty:
        print("No data matching the given filters.")
        return

    grouped = df.groupby('asn').agg({
        'cveId': lambda x: list(x),
        'asn': 'count'
    }).rename(columns={'asn': 'vulnerabilityCount'})

    top_asns = grouped.sort_values('vulnerabilityCount', ascending=False).head(50)

    output_rows = []
    for asn, row in top_asns.iterrows():
        all_cves = row['cveId']
        unique_cves = sorted(set(all_cves))

        row_data = {
            'asn': asn,
            'vulnerabilityCount': len(unique_cves) if args.count_only else len(all_cves),
            'networkType': 'Unknown'
        }

        if not args.count_only:
            row_data['cveIds'] = ', '.join(unique_cves)

        output_rows.append(row_data)

    if args.count_only:
        output_df = pd.DataFrame(output_rows, columns=['asn', 'vulnerabilityCount', 'networkType'])
    else:
        output_df = pd.DataFrame(output_rows, columns=['asn', 'vulnerabilityCount', 'cveIds', 'networkType'])

    output_df['networkType'] = output_df['asn'].apply(lambda asn: fetch_network_type_value(asn))

    output_df.to_csv(output_path, index=False)
    print(f"Output written to {output_path}")

if __name__ == '__main__':
    main()
