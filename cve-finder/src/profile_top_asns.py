import argparse
import pandas as pd
import os
import requests
from bs4 import BeautifulSoup
import time
import random 
import seaborn as sns
import matplotlib.pyplot as plt


def visualize_top_asns(csv_path):
    try:
        df = pd.read_csv(csv_path)

        if 'asn' not in df.columns or 'vulnerabilityCount' not in df.columns or 'networkType' not in df.columns:
            print("CSV is missing required columns: 'asn', 'vulnerabilityCount', 'networkType'")
            return

        #df['asn_label'] = df['asn'] .astype(str) + ' - ' + df['networkName']
        #df['asn_label'] = df['asn'] .astype(str) 

        def wrap_label(label, width=16):
            import textwrap
            return "\n".join(textwrap.wrap(label, width=width))



        df['asn_label'] =  df['networkName'].apply(wrap_label)


        plt.figure(figsize=(16, 8))

        sns.barplot(data=df, x='asn_label', y='vulnerabilityCount', hue='networkType', dodge=False, width = 0.8)

        plt.title('Top Networks by Vulnerability Count (Base Score 8.0+, Exploitability HIGH)')
        plt.xlabel('Network')
        plt.ylabel('Vulnerability Count')
        plt.xticks(rotation=0)
        plt.legend(title='Network Type')
        plt.tight_layout()

        plt.show()

    except Exception as e:
        print(f"Error while visualizing: {e}")

def parse_arguments():
    parser = argparse.ArgumentParser(description='Process CVE CSV and extract top ASN data.')
    parser.add_argument('--input_csv', default='found_cves.csv', help='Input CSV file name (default: found_cves.csv)')
    parser.add_argument('--base_score', type=float, default=None, help='Minimum base score to consider (optional)')
    parser.add_argument('--output_file', default='top_asns.csv', help='Output CSV file name (default: top_asns.csv)')
    parser.add_argument('--count_only', action='store_true', help='If set, output unique CVE count instead of listing them')
    parser.add_argument('--visualize-only', action = 'store_true', help='Skip the processing and generating of the csv. Only generates graphs')
    return parser.parse_args()


def fetch_network_name_and_type(asn):
    base_url = "https://bgp.tools/as/"
    url = f"{base_url}{asn}"
    headers = {
        "User-Agent": (
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
            "AppleWebKit/537.36 (KHTML, like Gecko) "
            "Chrome/114.0.0.0 Safari/537.36"
        ),
        "Accept-Language": "en-US,en;q=0.9",
    }

    try:
        response = requests.get(url, headers=headers, timeout=10)
        response.raise_for_status()
        soup = BeautifulSoup(response.text, 'html.parser')

        network_name_element = soup.find('p', id='network-name')
        network_name = network_name_element.get_text(strip=True) if network_name_element else "Unknown"


        for dt in soup.find_all('dt'):
            if dt.get_text(strip=True) == 'Network type':
                dd = dt.find_next_sibling('dd')
                if dd:
                    res = dd.get_text(strip=True)
                    print(f"AS{asn} -> {network_name} -> {res}")
                    return network_name, res
                else:
                    return network_name, "Unknown"
            
            wait_time = random.uniform(1.5, 4.0)
            time.sleep(wait_time)
    except Exception as e:
        print(f"Failed to fetch for ASN {asn}: {e}")
        return "Unknown", "Unknown"

def main():
    args = parse_arguments()

    script_dir = os.path.dirname(os.path.abspath(__file__))
    base_dir = os.path.abspath(os.path.join(script_dir, '..'))
    input_path = os.path.join(base_dir, args.input_csv)
    output_path = os.path.join(base_dir, args.output_file)

    if args.visualize_only:
        visualize_top_asns(output_path)
        return

    df = pd.read_csv(input_path)

    if args.base_score is not None:
        df = df[df['baseScore'] >= args.base_score]

    if df.empty:
        print("No data matching the given filters.")
        return

    grouped = df.groupby('asn').agg({
        'cveId': lambda x: list(x),
        'asn': 'count'
    }).rename(columns={'asn': 'vulnerabilityCount'})

    top_asns = grouped.sort_values('vulnerabilityCount', ascending=False).head(10)

    output_rows = []
    for asn, row in top_asns.iterrows():
        all_cves = row['cveId']
        unique_cves = sorted(set(all_cves))

        network_name, network_type = fetch_network_name_and_type(asn)

        row_data = {
            'asn': asn,
            'networkName': network_name,
            'vulnerabilityCount': len(all_cves),
            'networkType': network_type
        }

        if not args.count_only:
            row_data['cveIds'] = ', '.join(unique_cves)

        output_rows.append(row_data)

    if args.count_only:
        output_df = pd.DataFrame(output_rows, columns=['asn', 'networkName', 'vulnerabilityCount', 'networkType'])
    else:
        output_df = pd.DataFrame(output_rows, columns=['asn', 'networkName', 'vulnerabilityCount', 'cveIds', 'networkType'])

    output_df.to_csv(output_path, index=False)
    print(f"Output written to {output_path}")

if __name__ == '__main__':
    main()
